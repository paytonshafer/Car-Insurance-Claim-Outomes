{"cells":[{"attachments":{},"cell_type":"markdown","id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e","metadata":{},"source":["# Examining Features that are Most Likely to Lead to Filing a Claim\n","\n","Insurance companies spend a lot of time and money to optimize their pricing and trying to accuratly estimate the likelihood that a customer will file a claim. The goal of this notebook is to identify the best feature in the dataset to predict whether a customer will make a claim on their insurance during the policy period. I will create a simple Logistic Regression model for each  feature to indentify the single feature that results in the best perfroming model. The dataset constists of a plethora of features that describe a client and an outcome column that that notes if they have filed a claim. \n","\n","The data is saved as a csv file called `car_insurance.csv`. There is a table detailing the column names and descriptions below."]},{"attachments":{},"cell_type":"markdown","id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42","metadata":{},"source":["\n","\n","## The dataset\n","\n","| Column | Description |\n","|--------|-------------|\n","| `id` | Unique client identifier |\n","| `age` | Client's age: <br> <ul><li>`0`: 16-15</li><li>`1`: 26-39</li><li>`2`: 40-64</li><li>`3`: 65+</li></ul> |\n","| `gender` | Client's gender: <br> <ul><li>`0`: Female</li><li>`1`: Male</li></ul> |\n","| `driving_experience` | Years the client has been driving: <br> <ul><li>`0`: 0-9</li><li>`1`: 10-19</li><li>`2`: 20-29</li><li>`3`: 30+</li></ul> |\n","| `education` | Client's level of education: <br> <ul><li>`0`: No education</li><li>`1`: High school</li><li>`2`: University</li></ul> |\n","| `income` | Client's income level: <br> <ul><li>`0`: Poverty</li><li>`1`: Working class</li><li>`2`: Middle class</li><li>`3`: Upper class</li></ul> |\n","| `credit_score` | Client's credit score (between zero and one) |\n","| `vehicle_ownership` | Client's vehicle ownership status: <br><ul><li>`0`: Does not own their vehilce (paying off finance)</li><li>`1`: Owns their vehicle</li></ul> |\n","| `vehcile_year` | Year of vehicle registration: <br><ul><li>`0`: Before 2015</li><li>`1`: 2015 or later</li></ul> |\n","| `married` | Client's marital status: <br><ul><li>`0`: Not married</li><li>`1`: Married</li></ul> |\n","| `children` | Client's number of children |\n","| `postal_code` | Client's postal code | \n","| `annual_mileage` | Number of miles driven by the client each year |\n","| `vehicle_type` | Type of car: <br> <ul><li>`0`: Sedan</li><li>`1`: Sports car</li></ul> |\n","| `speeding_violations` | Total number of speeding violations received by the client | \n","| `duis` | Number of times the client has been caught driving under the influence of alcohol |\n","| `past_accidents` | Total number of previous accidents the client has been involved in |\n","| `outcome` | Whether the client made a claim on their car insurance (response variable): <br><ul><li>`0`: No claim</li><li>`1`: Made a claim</li></ul> |"]},{"attachments":{},"cell_type":"markdown","id":"49e65e50","metadata":{},"source":["First I am going to import the needed modules we need pandas, numpy and a function logit, from statsmodels. Once I have installed the propper packages I imported the data from a csv file using pandas. Next I examined the data using a few build in pandas functions to get the some insight on the data."]},{"cell_type":"code","execution_count":2,"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"executionCancelledAt":null,"executionTime":77,"id":"bA5ajAmk7XH6","lastExecutedAt":1689187044228,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n# Read in the Data set\ncars = pd.read_csv('car_insurance.csv')\n\n# Explore data\ncars.head()\ncars.info()\ncars.describe()","visualizeDataframe":false},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 18 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   10000 non-null  int64  \n"," 1   age                  10000 non-null  int64  \n"," 2   gender               10000 non-null  int64  \n"," 3   driving_experience   10000 non-null  object \n"," 4   education            10000 non-null  object \n"," 5   income               10000 non-null  object \n"," 6   credit_score         9018 non-null   float64\n"," 7   vehicle_ownership    10000 non-null  float64\n"," 8   vehicle_year         10000 non-null  object \n"," 9   married              10000 non-null  float64\n"," 10  children             10000 non-null  float64\n"," 11  postal_code          10000 non-null  int64  \n"," 12  annual_mileage       9043 non-null   float64\n"," 13  vehicle_type         10000 non-null  object \n"," 14  speeding_violations  10000 non-null  int64  \n"," 15  duis                 10000 non-null  int64  \n"," 16  past_accidents       10000 non-null  int64  \n"," 17  outcome              10000 non-null  float64\n","dtypes: float64(6), int64(7), object(5)\n","memory usage: 1.4+ MB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>credit_score</th>\n","      <th>vehicle_ownership</th>\n","      <th>married</th>\n","      <th>children</th>\n","      <th>postal_code</th>\n","      <th>annual_mileage</th>\n","      <th>speeding_violations</th>\n","      <th>duis</th>\n","      <th>past_accidents</th>\n","      <th>outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>9018.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>9043.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>500521.906800</td>\n","      <td>1.489500</td>\n","      <td>0.499000</td>\n","      <td>0.515813</td>\n","      <td>0.697000</td>\n","      <td>0.498200</td>\n","      <td>0.688800</td>\n","      <td>19864.548400</td>\n","      <td>11697.003207</td>\n","      <td>1.482900</td>\n","      <td>0.23920</td>\n","      <td>1.056300</td>\n","      <td>0.313300</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>290030.768758</td>\n","      <td>1.025278</td>\n","      <td>0.500024</td>\n","      <td>0.137688</td>\n","      <td>0.459578</td>\n","      <td>0.500022</td>\n","      <td>0.463008</td>\n","      <td>18915.613855</td>\n","      <td>2818.434528</td>\n","      <td>2.241966</td>\n","      <td>0.55499</td>\n","      <td>1.652454</td>\n","      <td>0.463858</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>101.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.053358</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10238.000000</td>\n","      <td>2000.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>249638.500000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.417191</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10238.000000</td>\n","      <td>10000.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>501777.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.525033</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>10238.000000</td>\n","      <td>12000.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>753974.500000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>0.618312</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>32765.000000</td>\n","      <td>14000.000000</td>\n","      <td>2.000000</td>\n","      <td>0.00000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>999976.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.960819</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>92101.000000</td>\n","      <td>22000.000000</td>\n","      <td>22.000000</td>\n","      <td>6.00000</td>\n","      <td>15.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  id           age        gender  credit_score  \\\n","count   10000.000000  10000.000000  10000.000000   9018.000000   \n","mean   500521.906800      1.489500      0.499000      0.515813   \n","std    290030.768758      1.025278      0.500024      0.137688   \n","min       101.000000      0.000000      0.000000      0.053358   \n","25%    249638.500000      1.000000      0.000000      0.417191   \n","50%    501777.000000      1.000000      0.000000      0.525033   \n","75%    753974.500000      2.000000      1.000000      0.618312   \n","max    999976.000000      3.000000      1.000000      0.960819   \n","\n","       vehicle_ownership       married      children   postal_code  \\\n","count       10000.000000  10000.000000  10000.000000  10000.000000   \n","mean            0.697000      0.498200      0.688800  19864.548400   \n","std             0.459578      0.500022      0.463008  18915.613855   \n","min             0.000000      0.000000      0.000000  10238.000000   \n","25%             0.000000      0.000000      0.000000  10238.000000   \n","50%             1.000000      0.000000      1.000000  10238.000000   \n","75%             1.000000      1.000000      1.000000  32765.000000   \n","max             1.000000      1.000000      1.000000  92101.000000   \n","\n","       annual_mileage  speeding_violations         duis  past_accidents  \\\n","count     9043.000000         10000.000000  10000.00000    10000.000000   \n","mean     11697.003207             1.482900      0.23920        1.056300   \n","std       2818.434528             2.241966      0.55499        1.652454   \n","min       2000.000000             0.000000      0.00000        0.000000   \n","25%      10000.000000             0.000000      0.00000        0.000000   \n","50%      12000.000000             0.000000      0.00000        0.000000   \n","75%      14000.000000             2.000000      0.00000        2.000000   \n","max      22000.000000            22.000000      6.00000       15.000000   \n","\n","            outcome  \n","count  10000.000000  \n","mean       0.313300  \n","std        0.463858  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        1.000000  \n","max        1.000000  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Import required modules\n","import pandas as pd\n","import numpy as np\n","from statsmodels.formula.api import logit\n","\n","# Read in the Dataset\n","cars = pd.read_csv('car_insurance.csv')\n","\n","# Explore data\n","cars.head()\n","cars.info()\n","cars.describe()"]},{"attachments":{},"cell_type":"markdown","id":"112572a0","metadata":{},"source":["After looking at the data we can see how many entries we have and how many non-null values in each column. I also get some statistical analysis on each column. I noted that credit_score and annual_mileage have missing values so I will fill all those values with the mean of the column. "]},{"cell_type":"code","execution_count":3,"id":"417420ab-3121-472d-95e5-516638506afa","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1689187044276,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Note that credit score and annual_mileage have missing values \n# Since they are normaly distributed we will fill with the mean\ncs_mean = np.mean(cars['credit_score'])\nam_mean = np.mean(cars['annual_mileage'])\n\n# Replace the na values in credit_score Column\ncars.fillna(cs_mean, inplace=True)\n\n# Replace the na values in annual_mileage Column\ncars.fillna(am_mean, inplace=True)\n\n# Note there are no Null columns now\ncars.info()"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 18 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   10000 non-null  int64  \n"," 1   age                  10000 non-null  int64  \n"," 2   gender               10000 non-null  int64  \n"," 3   driving_experience   10000 non-null  object \n"," 4   education            10000 non-null  object \n"," 5   income               10000 non-null  object \n"," 6   credit_score         10000 non-null  float64\n"," 7   vehicle_ownership    10000 non-null  float64\n"," 8   vehicle_year         10000 non-null  object \n"," 9   married              10000 non-null  float64\n"," 10  children             10000 non-null  float64\n"," 11  postal_code          10000 non-null  int64  \n"," 12  annual_mileage       10000 non-null  float64\n"," 13  vehicle_type         10000 non-null  object \n"," 14  speeding_violations  10000 non-null  int64  \n"," 15  duis                 10000 non-null  int64  \n"," 16  past_accidents       10000 non-null  int64  \n"," 17  outcome              10000 non-null  float64\n","dtypes: float64(6), int64(7), object(5)\n","memory usage: 1.4+ MB\n"]}],"source":["# Since they are normaly distributed we will fill with the mean\n","cs_mean = np.mean(cars['credit_score'])\n","am_mean = np.mean(cars['annual_mileage'])\n","\n","# Replace the na values in credit_score Column\n","cars.fillna(cs_mean, inplace=True)\n","\n","# Replace the na values in annual_mileage Column\n","cars.fillna(am_mean, inplace=True)\n","\n","# Note there are no Null columns now\n","cars.info()"]},{"attachments":{},"cell_type":"markdown","id":"727cca90","metadata":{},"source":["Note that there are no null columns in the data set anymore. Now to do some set up for the models I decalred a empty array for the models and got the list of features I will be examining."]},{"cell_type":"code","execution_count":4,"id":"0e01c6d2-4f9b-4792-8de3-0ac2b3c1af33","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1689187044328,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Next we will prepare to make the models \n# Declare empty list to hold models\nmodels = []\n\n# Create df of features \nfeatures = cars.drop(columns=['id', 'outcome']).columns\n\n# Look at a list of features we are looking at\nfeatures"},"outputs":[{"data":{"text/plain":["Index(['age', 'gender', 'driving_experience', 'education', 'income',\n","       'credit_score', 'vehicle_ownership', 'vehicle_year', 'married',\n","       'children', 'postal_code', 'annual_mileage', 'vehicle_type',\n","       'speeding_violations', 'duis', 'past_accidents'],\n","      dtype='object')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Next we will prepare to make the models \n","# Declare empty list to hold models\n","models = []\n","\n","# Create df of features \n","features = cars.drop(columns=['id', 'outcome']).columns\n","\n","# Look at a list of features we are looking at\n","features"]},{"attachments":{},"cell_type":"markdown","id":"378208fb","metadata":{},"source":["I will now build one model per feature and add it to the model list using the logit function and feeding the feature we want to use. Lastly I add the model to the model list."]},{"cell_type":"code","execution_count":null,"id":"5b7bbaac-a177-4c2b-ac99-c44a13c676f4","metadata":{"executionCancelledAt":null,"executionTime":2363,"lastExecutedAt":1689187046691,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Now we will build one model per feature and add it to the model list\n\n#loop through all the features\nfor f in features:\n    # Create a model\n    model = logit(f\"outcome ~ {f}\", data=cars).fit()\n    # Add each model to the models list\n    models.append(model)"},"outputs":[],"source":["#loop through all the features\n","for f in features:\n","    # Create a model\n","    model = logit(f\"outcome ~ {f}\", data=cars).fit()\n","    # Add each model to the models list\n","    models.append(model)"]},{"attachments":{},"cell_type":"markdown","id":"b1a09a8c","metadata":{},"source":["Now I will measure the preformance of each models using the confusion matrix and caldulating the accuracy. I then print out the accuracies to get an idea of the outcome."]},{"cell_type":"code","execution_count":6,"id":"b2859a78-537f-4677-9a56-35708b5f827a","metadata":{"executionCancelledAt":null,"executionTime":201,"lastExecutedAt":1689187046892,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Now we will measure the preformance of each model\n\n#Create a list to store the accuracies\naccuracies = []\n\n#loop through each model\nfor i in range(len(models)):\n    #create a confusion matrix\n    conf_mat = models[i].pred_table()\n    \n    #true negatives\n    tn = conf_mat[0,0]\n    #true positives\n    tp = conf_mat[1,1]\n    #false negatives\n    fn = conf_mat[0,1]\n    #false positives\n    fp = conf_mat[1,0]\n    \n    #calculate accuracy\n    accuracy = (tn + tp) / (tn + fn + fp + tp)\n    #add this to accuracies list\n    accuracies.append(accuracy)"},"outputs":[{"data":{"text/plain":["[0.7747,\n"," 0.6867,\n"," 0.7771,\n"," 0.6867,\n"," 0.7425,\n"," 0.7054,\n"," 0.7351,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867,\n"," 0.6867]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Create a list to store the accuracies\n","accuracies = []\n","\n","#loop through each model\n","for i in range(len(models)):\n","    #create a confusion matrix\n","    conf_mat = models[i].pred_table()\n","    \n","    #true negatives\n","    tn = conf_mat[0,0]\n","    #true positives\n","    tp = conf_mat[1,1]\n","    #false negatives\n","    fn = conf_mat[0,1]\n","    #false positives\n","    fp = conf_mat[1,0]\n","    \n","    #calculate accuracy\n","    accuracy = (tn + tp) / (tn + fn + fp + tp)\n","    #add this to accuracies list\n","    accuracies.append(accuracy)\n","    \n","# Examine the accuracies\n","accuracies"]},{"attachments":{},"cell_type":"markdown","id":"aae8d54f","metadata":{},"source":["Lastly using the accuracies I grab the max value in the array and find the feature with the same index. Lastly I created a best feature data frame to store the results in and printed the results. From this we can see that driving expirence is clearly the best single feature to determine if a customer will submit a claim."]},{"cell_type":"code","execution_count":7,"id":"1d4f777e-caee-4fd5-aba4-f581a053bd4e","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1689187046948,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Lastly we will examine the accuracies and pick the best feature to move forward with\n\n#find the index of the mac accuracy \nindex_of_max = accuracies.index(max(accuracies))\n\n#get the feature that goes with that index\nbest_feat = features[index_of_max]\n\n#Create the dataframe for the result and display\nbest_feature_df = pd.DataFrame({'best_feature': best_feat, 'best_accuracy':accuracies[index_of_max]}, index=[0])\n\n#Show the best feature with it's accuracy\nbest_feature_df"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>best_feature</th>\n","      <th>best_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>driving_experience</td>\n","      <td>0.7771</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         best_feature  best_accuracy\n","0  driving_experience         0.7771"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#find the index of the mac accuracy \n","index_of_max = accuracies.index(max(accuracies))\n","\n","#get the feature that goes with that index\n","best_feat = features[index_of_max]\n","\n","#Create the dataframe for the result and display\n","best_feature_df = pd.DataFrame({'best_feature': best_feat, 'best_accuracy':accuracies[index_of_max]}, index=[0])\n","\n","#Show the best feature with it's accuracy\n","best_feature_df"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
